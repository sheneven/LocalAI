{
    "sourceFile": "files/readPDFFiles.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 0,
            "patches": [
                {
                    "date": 1744338524361,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                }
            ],
            "date": 1744338524361,
            "name": "Commit-0",
            "content": "import os\nimport pdfplumber\nimport pandas as pd  # 导入Pandas库\nimport numpy as np  # 添加numpy库用于计算Z-score\nfrom config.GlobalConfig import ConfigSingleton # 导入mysqlUtil模块\nfrom utils.MysqlUtil import MySQLUtil\nfrom utils.AIUtils import model_chat, model_generate\nimport math\nimport traceback\nimport logging\n\n\ng_root_path = \"D:\\hr\\AI\\公共资源\\项目汇总(2)\\项目汇总\"\n\ncurrent_project_name = \"\"\nsys_message=\"\"\"\n    ## 角色：\n    你是一个数据分析专家和统计学顾问\n    ## 背景：\n    用户需要对投标打分表进行深度分析，目的是检验专家打分是否存在异常现象，如故意抬高或压低排名，以及是否存在对某投标人的偏向。这通常是为了确保招标过程的公正性和透明度，防止不正当竞争行为。\n    ## 技能：\n    你精通统计分析、数据挖掘、异常检测等技术，能够运用专业的统计软件和工具对数据进行深度分析，并通过逻辑推理和数据验证来得出准确的结论。\n    ## 目标\n      1. 对投标打分表进行初步的数据清洗和整理，确保数据的准确性和完整性。\n      2. 运用统计方法（如均值、标准差、方差分析、相关性分析等）分析专家打分的分布情况，识别是否存在异常打分。\n      3. 通过聚类分析、回归分析等方法，找出专家对某投标人的偏向性，判断是否存在故意抬高或压低排名的现象。\n      4. 提供详细的分析报告，包括数据可视化图表和结论，为用户决策提供依据。\n    ## 流程\n        1. 数据预处理：每一个投标人有一系列专家打分。此外还有投标人名称列，编号列，均分列，总分列。\n        2. 描述性统计分析：得到每个投标人的得分均值、标准差、方差等统计指标，分析专家打分的集中趋势和离散程度。\n        3. 异常检测与偏向性分析：运用聚类分析、回归分析等方法，识别专家打分中的异常模式和对某投标人的偏向性。\n        4. 结果呈现与报告撰写：撰写详细的分析报告，为用户提供决策支持。最后一句话总结\n    ## 要求\n    返回汇总记录，并对异常打分项进行分析，并给出原因。\n    ## 输出\n    分析报告应包括数据清洗过程、统计分析方法、异常检测结果、偏向性分析结论\n    \"\"\"\n# 预设的提示模板\nPROMPT_TEMPLATE = \"\"\"\n以下是一些数据：\n{data}\n请对这些数据进行分析，并给出结论。\n\"\"\"\ndef find_review_summary_pdfs(root_folder):\n    print(\"find_review_summary_pdfs\")\n    review_summaries = []\n    current_project_name = ''\n    for project_folder in os.listdir(root_folder):\n        project_path = os.path.join(root_folder, project_folder)\n        if os.path.isdir(project_path):\n            # 把文件夹名称赋值给变量current_project_name\n            current_project_name = project_folder\n            for file_name in os.listdir(project_path):\n                if '评审汇总' in file_name and (file_name.lower().endswith('.pdf') or file_name.lower().endswith('.PDF') ):\n                    print(f\"Found review summary PDF: {file_name}\")\n                    review_summaries.append(os.path.join(project_path, file_name))\n    return review_summaries\n\ndef extract_tables_from_pdf(pdf_path, output):\n    tables = []\n    project_name = pdf_path.split('\\\\')[-2]\n    with pdfplumber.open(pdf_path) as pdf:\n        for page in pdf.pages:\n            tables.extend(page.extract_tables())\n    # 将每个表格转换为Pandas DataFrame\n    # 将所有colum中的换行去掉，并换成拼音开头\n    import pypinyin\n    dataframes = []\n    start_ex = 0\n    end_ex = 0\n    index = -1\n    try:\n        for col in tables[0][0]:\n            index += 1\n            print(\"col:\", col)\n            if col:\n                if col.startswith('技术'):\n                    start_ex = index\n                    continue\n                if col.startswith('商务'):\n                    end_ex = index\n                    break\n    except:\n        print(\"error\")\n    print(start_ex)\n    print(end_ex)\n    merge_table = []\n    for table in tables:\n        for row in table:\n            merge_table.append(row)\n    print(len(merge_table))\n    # 去掉列名中的换行符并转换为拼音\n    (conclusion, df) = parse_one_table(merge_table, start_ex, end_ex, project_name)  # 修改：传递project_name参数\n    output.AppendText(conclusion)\n    dataframes.append(df)\n    return dataframes\n#对单个表进行处理\ndef parse_one_table(table, start, end, project_name):\n    try:\n        # 去掉列名中的换行符并转换为拼音\n        print(\"table:\", table)\n        output_path = f\"{project_name}_table.csv\"\n\n        columns = table[0]\n        print(\"columns:\", columns)\n        df = pd.DataFrame(table[1:], columns=columns)  # 修改：从第二行开始作为数据\n        df.to_csv(\"text.csv\", index=False)\n        print(f\"df_score exported to {output_path}\")\n        \n        df_score = df.iloc[:, 0:end]  # 修改：使用方括号而不是圆括号\n        # 修改：生成与df_score列数相同的名称列表\n        print(table[0])\n        print(table[1])\n        new_column_names = table[0][:2] + table[1][2:end]\n        print(\"new_column_names:\", new_column_names)\n        # 列名去掉所有换行符\n        columns_clean = [col.replace('\\n', '') if col else '投标人名称' for col in new_column_names]\n        # 设置新的列名\n        df_score.columns = columns_clean\n        print(\"========new df is \")\n        #去掉第二行\n        df_score = df_score.drop(df_score.index[0])\n        df_score = df_score.drop(df_score.index[-1])\n        df_score = df_score.drop(df_score.index[-1])\n        #对列名为投标人名称的列，去掉所有\\n符号\n        df_score['投标人名称'] = df_score['投标人名称'].str.replace('\\n', '')\n        #print(df_score)\n        # 增加一列项目，标明项目名称\n        # 使用 .loc 来设置新列 '项目' 的值\n        df_score.loc[:, '项目'] = project_name\n        # 导出df_score为CSV文件\n        df_score.to_csv(output_path, index=False, encoding='utf-8')\n        #findout_except_expert_by_ai(df_score)\n        #给出第一个专家和最后一个专家的index\n        #conclusion = findout_except_expert(df_score, start, end-2,project_name )\n        df_score_json = df_score.to_json(orient='records', force_ascii=False)\n        conclusion = findout_except_expert_by_ai(df_score_json)\n        print(conclusion)\n        with open(\"结果.txt\",\"a\")  as f:\n            f.write(conclusion)\n        print(f\"df_score exported to {output_path}\")\n        return (conclusion,df_score)\n    except Exception as e:\n        print(\"Error1:\", e)\n        return None\n# 添加AI分析部分，检测评分异常的专家\ndef findout_except_expert_by_ai(str_conclusion):\n    global PROMPT_TEMPLATE,sys_message\n    conclussion = \"\"\n    str_index = \"\"\n    try:\n        #data_str = df_score.to_string(index=False)\n        data_str = f\"现在有专家对投标人打分，已经发现了打分异常，请综合分析，并找出专家偏向的投标企业:{str_conclusion}\"\n        print(\"prompt:\", PROMPT_TEMPLATE.format(data=data_str))\n        query = PROMPT_TEMPLATE.format(data=data_str)\n        conclussion = model_generate(query, \"deepseek-r1:32b\",sys_message)\n        print(\"conclussion:\", conclussion)\n        str_index = conclussion[conclussion.find(\"</think>\")+9:]\n    except Exception as e:\n        stack_trace = traceback.format_exc()\n        print(\"stack_trace:\", stack_trace)\n    finally:\n        print(\"findout_except_expert_by_ai\")\n        return str_index\n\n#根据平均分排序和专家打分排序，鉴定专家打分异常\ndef compare_expert_score(df_standard, df_expert):\n    # 确保两个DataFrame都有 '投标人名称' 列\n    if '投标人名称' not in df_standard.columns or '投标人名称' not in df_expert.columns:\n        raise ValueError(\"Both DataFrames must have a '投标人名称' column.\")\n    try:\n        # 创建一个字典来存储 df_expert 中的投标人名称及其对应的索引\n        expert_index_map = {name: idx for idx, name in enumerate(df_expert['投标人名称'])}\n        discrepancies = []\n        print(\"expert_index_map:\", expert_index_map)\n        \n        # 遍历 df_standard 中的投标人名称\n        for std_idx, std_name in enumerate(df_standard['投标人名称']):\n            print(f\"std_idx:{std_idx},std_name:{std_name}\")\n            try :\n                if std_name in expert_index_map:\n                    exp_idx = expert_index_map[std_name]\n                    if std_idx == None or exp_idx == None:\n                        print(f\"{std_name} is  none\")\n                        continue\n                    #计算排名差的绝对值\n                    '''\n                    print(f\"{std_name} now\")\n                    print(std_idx != exp_idx )\n                    print(abs(int(exp_idx) - int(std_idx))  )\n                    '''\n                    if std_idx != exp_idx and abs(int(exp_idx) - int(std_idx)) > 1 :\n                        discrepancies.append((std_name,int(std_idx) + 1, int(exp_idx) + 1))  # 从1开始计数\n                else:\n                    # 如果 df_expert 中没有找到对应的投标人名称，可以记录下来\n                    discrepancies.append((std_name,int(std_idx) + 1, None))\n            except Exception as e:\n                print(f\"Error processing {std_name}: {e}\")\n                continue\n        # 如果没有不一致的情况，返回 \"顺序一致\"\n        if not discrepancies:\n            return None\n        print(\"discrepancies:\", discrepancies)\n        \n        # 返回不一致的位置\n        return discrepancies\n    except Exception as e:\n        print(\"Error2:\", e)\n        return None\n# 添加AI分析部分，检测评分异常的专家\ndef findout_except_expert(df_score, start, end,project):\n    try:\n\n        print(\"find out\")\n        #将评标人的平均分排序。假设评标人是第二列\n        #df_score['平均分'] = df_score.iloc[:, 1:-3].mean(axis=1)\n        df_score.sort_values(by='均分', ascending=False, inplace=True)\n        print(\"排名后\")\n        #print(df_score)\n        # 查找列名对应的位置\n        column_name = '投标人名称'\n        column_index = df_score.columns.get_loc(column_name)    \n        #复制投标人名称一栏\n        standard_df = df_score[['投标人名称', '均分']].copy()\n        #对评标人平均分排序\n        standard_df.sort_values(by='均分', ascending=False, inplace=True)\n        print(standard_df)\n        #给每个专家的打分进行排序，看是否和评标人平均分排序相吻合\n        print(\"before loop\")\n        conclusion = f\"====\\n项目{project}的校验结果：\\n\"\n        for i in range(start, end):\n            try:\n                column_data = df_score.iloc[:, [column_index, i]]  # 第i列数据\n                #print(column_data)\n                #colum_data根据第二列排序\n                column_data = column_data.reset_index(drop=True)\n                #print(column_data.columns[1])\n                column_data.sort_values(by=column_data.columns[1], ascending=False, inplace=True)\n                print(f\"第{i}列：{column_data}\")\n                #print(f\"数据：\\n{column_data}\\n\")\n                result = compare_expert_score(column_data, standard_df)\n                if result != None:\n                    for item in result:\n                        print(f\"投标人名称：{item[0]}，评标人平均分：{item[1]}，专家打分：{item[2]}\")\n                        conclusion += f\"专家{df_score.columns[i]}对{item[0]}打分排名[{item[2]}]和评标人平均分排名[{item[1]}]不一致，请检查。\\n\"\n            except Exception as e:\n                error_info = traceback.format_exc()\n                print(\"捕获到异常，完整信息如下：\")\n                print(error_info)\n                continue\n        if len(conclusion) <= 0:\n            print(conclusion)\n            return \"一切正常\"\n        else:\n            return conclusion\n    except Exception as e:\n        print(\"error3\",e)\n#结构化专家表信息，使其可以存储到数据库中\ndef chg_expert_data(df):\n    result_map=[]\n    for index,row in df.iterrows():\n        one_score = {}\n        print(row)\n        print()\n    pass\ndef main(mysqlUtil, g_root_path , output_text):\n    with open(\"结果.txt\",\"a\")  as f:\n        f.write(\"\")\n    print(\"Processing started...\")\n    #global g_root_path\n    root_folder = g_root_path  # Use the provided folder path\n    review_summaries = find_review_summary_pdfs(root_folder)\n    print(f\"Found PDFs: {review_summaries}\")\n    index = 1\n    total = len(review_summaries)\n    \n    for pdf_path in review_summaries:\n        print(f\"Processing PDF: {pdf_path}\")\n        output_text.AppendText(f\"处理 PDF({index}/{total})\\n {pdf_path}\\n\")\n        dataframes = extract_tables_from_pdf(pdf_path, output_text)\n        index += 1\n        for i, df in enumerate(dataframes):\n            print(f\"Table {i+1}:\")\n            print(df)\n            print(\"\\n\" + \"-\"*50 + \"\\n\")\n            # Optionally handle database operations here if needed\n"
        }
    ]
}