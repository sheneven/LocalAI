{
    "sourceFile": "tools/webpage_screenshot.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 1,
            "patches": [
                {
                    "date": 1744613441723,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1744613508693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -437,8 +437,12 @@\n     data = request.get_json()\n     url = data.get('url')\n     if not url:\n         return jsonify({\"error\": \"缺少 URL 参数\"}), 400\n+    return spider_web(url)\n+    \n+def spider_web(url):\n+\n     global result_map\n     result_map = {}    \n     # 生成唯一的截图文件名\n     output_path = f\"./{int(time.time())}_screenshot.png\"\n"
                }
            ],
            "date": 1744613441723,
            "name": "Commit-0",
            "content": "from flask import Flask, request, jsonify\nfrom selenium import webdriver\nfrom selenium.webdriver.chrome.service import Service\nfrom selenium.webdriver.common.by import By  # 导入 By 类\nimport time\nimport requests\nimport os\nfrom selenium.webdriver.common.action_chains import ActionChains\nimport base64\nfrom bs4 import BeautifulSoup\nimport json\n\n\napp = Flask(__name__)\nresult_map = {}\n\n# 去除HTML标签的函数\ndef remove_html_tags(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    return soup.get_text()\ndef image_to_base64(image_path):\n    \"\"\"\n    将图片文件转换为 Base64 编码字符串\n    :param image_path: 图片文件的路径\n    :return: 图片的 Base64 编码字符串\n    \"\"\"\n    with open(image_path, \"rb\") as image_file:\n        encoded_string = base64.b64encode(image_file.read()).decode('utf-8')\n    return encoded_string\n\ndef capture_screenshot(url, output_path):\n    global result_map\n    try:\n        # 设置 ChromeDriver 的路径\n        #service = Service(r'C:\\Program Files\\Google\\Chrome\\Application\\chromedriver-win64')\n        # 创建 Chrome 浏览器实例\n        #driver = webdriver.Chrome(service=service)\n        options = webdriver.ChromeOptions()\n        # 设置启动参数，指定页面缩放比例，例如设置为50%\n        options.add_argument(\"--force-device-scale-factor=0.75\")\n        driver = webdriver.Chrome(options=options)\n        #driver = webdriver.Chrome()\n\n        # 打开指定的网页\n        driver.get(url)\n\n        # 等待页面加载，可根据实际情况调整等待时间\n        time.sleep(15)\n        # 根据 article 的 id 定位 article 元素\n        article = driver.find_element(By.ID, \"douyin_login_comp_flat_panel\")\n\n        # 在 article 元素内查找 svg 元素\n        svg_element = article.find_element(By.TAG_NAME, \"svg\")    \n        svg_element.click()\n        print(\"点击了按钮，等4秒\")\n        time.sleep(8)\n        if url.index(\"\") > 0:\n            get_info_by_page_video(driver)\n        else:\n            get_info_by_page_note(driver)\n        #去截图\n        actions = ActionChains(driver)\n        actions.scroll_by_amount(0, 500).perform()\n\n        #driver.execute_script(\"window.scrollBy(0, 500);\")\n        print(\"滚动了500像素\")\n        time.sleep(3)\n        # 截取整个页面的截图\n        driver.save_screenshot(output_path)\n        print(f\"截图已保存到 {output_path}\")\n\n    except Exception as e:\n        print(f\"发生错误: {e}\")\n    finally:\n        # 关闭浏览器\n        if 'driver' in locals():\n            driver.quit()\ndef get_info_by_page_note(driver):\n    print(\"enter in note\")\n    global result_map\n    try:\n        #data-e2e=\"user-info\"\n        element_userinfo = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"user-info\"]')\n        soup_user = BeautifulSoup(element_userinfo.get_attribute('outerHTML'), 'html.parser')\n\n        ##获取作者信息\n        element = driver.find_element(By.CSS_SELECTOR, '[data-click-from=\"title\"]')\n        print(element.get_attribute('outerHTML'))\n        soup = BeautifulSoup(element.get_attribute('outerHTML'), 'html.parser')\n          # 使用 find 方法\n        if soup:\n            print(soup.get_text())\n            text = soup.get_text()\n            result_map[\"auth_name\"] = text\n            print(\"获取到的文本是:\", text)\n        else:\n            print(\"未找到目标元素。\")\n        try:\n            ##获取点赞等信息\n            #data-e2e=\"video-share-icon-container\"\n            #data-e2e=\"video-player-collect\"\n            comment_name_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"video-player-collect\"]')\n            zan_list = []\n            if comment_name_element:\n                print(\"select zan\")# 查找 comment_name_element 的父亲节点\n                parent_element = comment_name_element.find_element(By.XPATH, \"..\")\n                \n                #查找到他的父亲节点\n                zan_soup = BeautifulSoup(parent_element.get_attribute('outerHTML'), 'html.parser')\n                if zan_soup:\n                    list_zan = zan_soup.find_all(\"div\")\n                    print(\"len is \")\n                    print(len(list_zan))\n                    index = 0\n                    for item in zan_soup.find_all(\"div\")[0].children:\n                        if index > 1:\n                            #只收集前两个\n                            break\n                        try:\n                            print(item)\n                            #print(item.get_attribute('outerHTML'))\n                            #print(item.get_text(()))\n                            #text = remove_html_tags(item.get_attribute('outerHTML'))\n                            #print()\n                            if None == item.find_all(\"div\"):\n                                print(\"未找到div\")\n                                continue\n                            if len(item.find_all(\"div\")[0]) > 1:\n                                #print(item.find_all(\"div\")[0].get_attribute('outerHTML'))\n                                print(item.find_all(\"div\")[0].get_text())\n                                print(\"enter find all\")\n                                text = item.find_all(\"div\")[0].find_all(\"div\")[1].get_text()\n                                print(\"add list \"+text)\n                                zan_list.append(str(text))\n\n                        except Exception as e:\n                            print(f\"发生错误: {e}\")\n                            zan_list.append(\"0\")\n                        finally:\n                            index = index + 1\n                        '''\n                        print(item.find_all(\"div\")[0].find_all(\"div\"))\n                        #text = item.find_all(\"div\")[0].find_all(\"div\")[1]\n                        if text:\n                            zan_list.append(str(text.get_text()))\n                        else:\n                            zan_list.append(\"0\")\n                            print(\"未找到文本\")\n                        print(str(text.get_text()))\n                        '''\n                #查找点赞数和转发数        \n                sz_soup = BeautifulSoup(comment_name_element.get_attribute('outerHTML'), 'html.parser')\n                #print(sz_soup.find_element(By.XPATH, './/div[1]').get_text())\n                for text_item in sz_soup.children:\n                    if text_item.name == \"div\":\n                        print(text_item.get_text())\n                        sz = text_item.get_text()\n                        print(f\"收藏:{sz}\")\n                        zan_list.append(sz)\n                        break\n                #sz = sz_soup.children[1].get_text\n                #sz = sz_soup.find_all(\"div\")[1].get_text\n\n                #print(f\"收藏{sz}\")\n                #zan_list.append(sz)\n                #data-e2e=\"video-player-share\"\n                comment_name_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"video-player-share\"]')\n                dz_soup = BeautifulSoup(comment_name_element.get_attribute('outerHTML'), 'html.parser')\n                for text_item in sz_soup.children:\n                    if text_item.name == \"div\":\n                        print(text_item.get_text())\n                        sz = text_item.get_text()\n                        print(f\"分享:{sz}\")\n                        zan_list.append(sz)\n                        break\n                print(zan_list)\n                if len(zan_list) > 0:\n                    result_map[\"点赞数\"] = zan_list[0] if str.isdigit(zan_list[0]) else '0'\n                    result_map[\"评论数\"] = zan_list[1] if str.isdigit(zan_list[1]) else '0'\n                    result_map[\"收藏数\"] = zan_list[2] if str.isdigit(zan_list[2]) else '0'\n                    result_map[\"转发数\"] = zan_list[3] if str.isdigit(zan_list[3]) else '0'\n                else:\n                    result_map[\"点赞数\"] = '0'\n                    result_map[\"评论数\"] = '0'\n                    result_map[\"收藏数\"] = '0'\n                    result_map[\"转发数\"] = '0'            \n        except Exception as e:\n            print(e)\n        print(\"====================\")\n        print(result_map)\n        try:\n            ##获取认证信息\n            #data-e2e=\"badge-role-name\"\n            auth_name_element = element.find_element(By.CSS_SELECTOR, '[data-e2e=\"badge-role-name\"]')\n            if auth_name_element:\n                print(\"找到的元素文本内容：\", auth_name_element)\n                auth_soup = BeautifulSoup(auth_name_element.get_attribute('outerHTML'), 'html.parser')\n                text = auth_soup.find(\"span\").get_text()\n                result_map[\"v_name\"] = text\n            else:\n                print(\"未找到元素\")\n            print(f\"result_map:{result_map}\")\n        except Exception as e:\n            print(f\"发生错误：{e}\")\n        ##获取粉丝数\n        target_text = \"粉丝\"\n        # 通过文本查找元素\n        print(element_userinfo.get_attribute('outerHTML'))\n        target_element = soup_user.find(string=target_text)\n\n        if target_element:\n            # 获取该元素的父元素\n            parent_element = target_element.parent.parent\n            if parent_element:\n                print(\"父元素的 HTML 内容：\")\n                print(parent_element.prettify())\n                fss=parent_element.find_all(\"span\")[1]\n                print(f\"fss:\"+fss.get_text())\n                if fss:\n                    result_map[\"fans\"] = fss.get_text()\n                    print(f\"粉丝数：{fss.get_text()}\")\n                else:\n                    result_map[\"fans\"] = \"0\"\n                    print(\"未找到粉丝数\")\n                #获取所有子级元素\n\n            else:\n                print(\"未找到父元素。\")\n        else:\n            print(\"未找到包含目标文本的元素。\")\n\n\n        #获取发布时间\n        #data-e2e=\"detail-video-publish-time\"\n        time_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"detail-video-publish-time\"]')\n        if time_element:\n            print(\"找到的元素文本内容：\", time_element)\n            auth_soup = BeautifulSoup(time_element.get_attribute('outerHTML'), 'html.parser')\n            text = auth_soup.get_text()\n            result_map[\"publish_time\"] = text\n        else:\n            print(\"未找到元素\")     \n    except print(0):\n        pass\n\n#通过页面元素获取信息-video版\ndef get_info_by_page_video(driver):\n    print(\"enter in video\")\n    global result_map\n    try:\n        #data-e2e=\"user-info\"\n        element_userinfo = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"user-info\"]')\n        soup_user = BeautifulSoup(element_userinfo.get_attribute('outerHTML'), 'html.parser')\n\n        ##获取作者信息\n        element = driver.find_element(By.CSS_SELECTOR, '[data-click-from=\"title\"]')\n        print(element.get_attribute('outerHTML'))\n        soup = BeautifulSoup(element.get_attribute('outerHTML'), 'html.parser')\n        target_element = soup.find('div').find('span')  # 使用 find 方法\n        if target_element:\n            text = target_element.get_text()\n            result_map[\"auth_name\"] = text\n            print(\"获取到的文本是:\", text)\n        else:\n            print(\"未找到目标元素。\")\n        try:\n            ##获取点赞等信息\n            #data-e2e=\"video-share-icon-container\"\n            comment_name_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"video-player-collect\"]')\n            zan_list = []\n            if comment_name_element:\n                print(\"select zan\")# 查找 comment_name_element 的父亲节点\n                parent_element = comment_name_element.find_element(By.XPATH, \"..\")\n                \n                #查找到他的父亲节点\n                zan_soup = BeautifulSoup(parent_element.get_attribute('outerHTML'), 'html.parser')\n                if zan_soup:\n                    list_zan = zan_soup.find_all(\"span\")\n                    print(\"len is \")\n                    print(len(list_zan))\n                    for item in list_zan:\n                        zan_list.append(str(item.get_text()))\n                        print(str(item.get_text()))\n                    \n                print(zan_list)\n                if len(zan_list) > 0:\n                    #如果不是数字类型，则返回0\n                    result_map[\"点赞数\"] = zan_list[0] if isinstance(zan_list[0], int) else '0'\n                    result_map[\"评论数\"] = zan_list[1] if isinstance(zan_list[1], int) else '0'\n                    result_map[\"收藏数\"] = zan_list[2] if isinstance(zan_list[2], int) else '0'\n                    result_map[\"转发数\"] = zan_list[3] if isinstance(zan_list[3], int) else '0'\n                else:\n                    result_map[\"点赞数\"] = '0'\n                    result_map[\"评论数\"] = '0'\n                    result_map[\"收藏数\"] = '0'\n                    result_map[\"转发数\"] = '0'\n                '''\n                if parent_element:\n                    print(\"父元素的 HTML 内容：\")\n                    print(parent_element.prettify())\n                    comment_soup = BeautifulSoup(parent_element.get_attribute('outerHTML'), 'html.parser')\n\n                    print(f\"dz:\"+comment_soup.get_text())\n                    if dz:\n                        result_map[\"fans\"] = dz.get_text()\n                        print(f\"点赞数：{dz.get_text()}\")\n                    else:\n                        result_map[\"fans\"] = \"0\"\n                        print(\"未找到点赞数\")\n            else:\n                print(\"未找到元素\")\n            '''\n            \n        except Exception as e:\n            print(e)\n        try:\n            ##获取认证信息\n            #data-e2e=\"badge-role-name\"\n            auth_name_element = element.find_element(By.CSS_SELECTOR, '[data-e2e=\"badge-role-name\"]')\n            if auth_name_element:\n                print(\"找到的元素文本内容：\", auth_name_element)\n                auth_soup = BeautifulSoup(auth_name_element.get_attribute('outerHTML'), 'html.parser')\n                text = auth_soup.find(\"span\").get_text()\n                result_map[\"v_name\"] = text\n            else:\n                print(\"未找到元素\")\n            print(f\"result_map:{result_map}\")\n        except Exception as e:\n            print(f\"发生错误：{e}\")\n        ##获取粉丝数\n        target_text = \"粉丝\"\n        # 通过文本查找元素\n        print(element_userinfo.get_attribute('outerHTML'))\n        target_element = soup_user.find(string=target_text)\n\n        if target_element:\n            # 获取该元素的父元素\n            parent_element = target_element.parent.parent\n            if parent_element:\n                print(\"父元素的 HTML 内容：\")\n                print(parent_element.prettify())\n                fss=parent_element.find_all(\"span\")[1]\n                print(f\"fss:\"+fss.get_text())\n                if fss:\n                    result_map[\"fans\"] = fss.get_text()\n                    print(f\"粉丝数：{fss.get_text()}\")\n                else:\n                    result_map[\"fans\"] = \"0\"\n                    print(\"未找到粉丝数\")\n                #获取所有子级元素\n\n            else:\n                print(\"未找到父元素。\")\n        else:\n            print(\"未找到包含目标文本的元素。\")\n\n\n        #获取发布时间\n        #data-e2e=\"detail-video-publish-time\"\n        time_element = driver.find_element(By.CSS_SELECTOR, '[data-e2e=\"detail-video-publish-time\"]')\n        if time_element:\n            print(\"找到的元素文本内容：\", time_element)\n            auth_soup = BeautifulSoup(time_element.get_attribute('outerHTML'), 'html.parser')\n            text = auth_soup.get_text()\n            result_map[\"publish_time\"] = text\n        else:\n            print(\"未找到元素\")     \n    except print(0):\n        pass\n# 去除HTML标签的函数\ndef remove_html_tags(text):\n    soup = BeautifulSoup(text, 'html.parser')\n    return soup.get_text()\ndef ollama_identify_image(image_path):\n    ollama_api_url = \"http://10.0.0.7:11434/api/generate\"\n    headers = {\n        \"Content-Type\": \"application/json\"\n    }\n    base64_image = image_to_base64(image_path)\n    print(\"img path\"+image_path)\n    #print(\"img base64\"+base64_image)\n    #其中心是点赞，对话图标是评论，星是收藏，向右箭头是转发，后面的数字是他们的数量。\n    prompt =\"\"\"你是一个OCR助手。请返回图片的点赞数，评论数，收藏数，转发数\n    心形标志是点赞，心形右侧的数字是点赞数；点赞数右侧的标志是评论，评论右侧的数字是评论数；\n    评论数右侧的五角星是收藏，收藏右侧的数字是收藏数；收藏数右侧的向右箭头是转发，转发右侧的数字是转发数。\n    没找到的字段显示为0，不要瞎写。\n    仅提供转录，不要有任何额外的评论。\n    返回格式参照如下：\n    {\"点赞数\": 0,\"评论数\": 0,\"收藏数\": 0,\"转发数\": 0}\n    \"\"\"\n    prompt_new = \"请结构化输出图片内容\"\n    \n    try:\n        # 构建请求数据\n        data = {\n            \"model\": \"minicpm-v:latest\",\n            #\"model\": \"deepseek-r1:32b\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": prompt,\n                    \"images\": [base64_image],\n                    \"temperature\": 0.3\n\n                }\n            ],\n            \"stream\": False\n        }\n        #print(data)\n        '''\n        # 构建请求体\n        data = {\n            \"model\": \"deepseek-r1:32b\",\n            \"prompt\": f\"识别这张图片，并返回点赞数，评论数，收藏数，转发数。其中心是点赞，对话图标是评论，星是收藏，箭头转发: {encoded_image}\"\n        }\n        '''\n        \n        # 发送 POST 请求\n        response = requests.post(ollama_api_url, headers=headers, json=data)\n        \n        if response.status_code == 200:\n            print(f\"Ollama 响应: {response.text}\")\n            return response.json()\n        else:\n            print(f\"Ollama 请求失败: {response.text}\")\n            return None\n    except Exception as e:\n        print(f\"发生错误: {e}\")\n        return None\n\n\n@app.route('/screenshot_and_identify', methods=['POST'])\ndef screenshot_and_identify():\n    if request.content_type != 'application/json':\n        return jsonify({\"error\": \"请求头 Content-Type 必须是 application/json\"}), 400\n\n    data = request.get_json()\n    url = data.get('url')\n    if not url:\n        return jsonify({\"error\": \"缺少 URL 参数\"}), 400\n    global result_map\n    result_map = {}    \n    # 生成唯一的截图文件名\n    output_path = f\"./{int(time.time())}_screenshot.png\"\n    capture_screenshot(url, output_path)\n    \n    result = ollama_identify_image(output_path)\n    print(result)\n    '''\n    # 删除临时截图文件\n    if os.path.exists(output_path):\n        os.remove(output_path)\n    '''\n    #print( result.json().get(\"message\", {}).get(\"content\", \"\"))\n    if result:\n        print(result.get(\"message\", {}).get(\"content\", \"\"))\n        #将result_map和result.get(\"message\", {}).get(\"content\", \"\")合并\n        #global result_map\n        print(\"global result_map\")\n        dict1 = {}\n        content = result.get(\"message\", {}).get(\"content\", \"\")\n        try:\n            dict1 = json.loads(content)  # 使用 json.loads 解析字符串为字典\n        except json.JSONDecodeError as e:\n            print(f\"解析字符串为字典时发生错误: {e}\")\n            dict1 = {}\n        merged_dict = {**result_map, **dict1}  # 使用**运算符合并两个字典\n        #result_map.update(result.get(\"message\", {}).get(\"content\", \"\"))\n        print(merged_dict)\n        \n        #return jsonify({\"success\": result.get(\"message\", {}).get(\"content\", {})})\n        return jsonify(merged_dict)\n\n    else:\n        return jsonify({\"error\": \"识别失败\"}), 500\n    \n    #return jsonify({\"message\": \"截图成功\"}), 200\n\nif __name__ == \"__main__\":\n    app.run(debug=True, host='0.0.0.0')\n"
        }
    ]
}